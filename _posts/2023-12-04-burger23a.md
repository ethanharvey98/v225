---
title: Multi-modal Graph Learning over UMLS Knowledge Graphs
abstract: Clinicians are increasingly looking towards machine learning to gain insights
  about patient progression. We propose a novel approach named Multi-Modal UMLS Graph
  Learning (MMUGL) for learning meaningful representations of medical concepts using
  graph neural networks over knowledge graphs based on the unified medical language
  system. These concept representations are aggregated to represent a patient visit
  and then fed into a sequence model to perform predictions at the granularity of
  multiple hospital visits of a patient. We improve performance by incorporating prior
  medical knowledge and considering multiple modalities. We compare our method to
  existing architectures proposed to learn representations at different granularities
  on the MIMIC-III dataset and show that our approach outperforms these methods. The
  results demonstrate the significance of multi-modal medical concept representations
  based on prior medical knowledge. We provide our code on GitHub https://github.com/ratschlab/mmugl
  .
software: https://github.com/ratschlab/mmugl
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: burger23a
month: 0
tex_title: Multi-modal Graph Learning over UMLS Knowledge Graphs
firstpage: 52
lastpage: 81
page: 52-81
order: 52
cycles: false
bibtex_author: Burger, Manuel and R\"atsch, Gunnar and Kuznetsova, Rita
author:
- given: Manuel
  family: Burger
- given: Gunnar
  family: RÃ¤tsch
- given: Rita
  family: Kuznetsova
date: 2023-12-04
address: 
container-title: Proceedings of the 3rd Machine Learning for Health Symposium
volume: '225'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 12
  - 4
pdf: https://proceedings.mlr.press/v225/burger23a/burger23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
